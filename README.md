# Jordan Electronics Scraper ğŸ›’

A comprehensive web scraping pipeline for monitoring electronics products and prices from major Jordanian retailers. This project collects product data from SmartBuy Jordan and Leaders Center Jordan, storing it in MongoDB for analysis and tracking.

**âœ¨ Recently refactored to hybrid architecture for better maintainability and code reuse!**

**ğŸ†• Week 2: Enhanced categorization system with 85.2% accuracy and Arabic language support!**

**ğŸ”§ Latest Updates (September 26, 2025):**

- **SmartBuy Scraper Debugging**: Fixed Unicode encoding issues for Windows terminal compatibility
- **Website Structure Adaptation**: Updated for SmartBuy's `/collections/` and `/products/` URL patterns  
- **Category Discovery Enhancement**: Now discovers 198+ product collections automatically
- **Brand-Based Collections**: Added support for Apple, Samsung, Sony, ASUS, and 12+ other brands
- **Comprehensive Testing**: All scrapers tested and verified working on latest website structures
- **Categorization Bug Fix**: Resolved ASUS VivoBook misclassification issue with improved brand pattern matching

## ğŸ¯ Project Overview

This scraping pipeline is designed to:
- Monitor electronics prices across Jordanian retailers
- Collect comprehensive product information
- Store data in a flexible MongoDB database
- Provide foundation for price tracking and market analysis

### Target Websites
- **SmartBuy Jordan**: https://smartbuy-me.com
- **Leaders Center Jordan**: https://www.leaders.jo

## ğŸ“‹ Features

- âœ… **Multi-Site Scraping**: Supports SmartBuy and Leaders websites
- âœ… **Smart Field Detection**: Dynamic currency, source, and category detection
- âœ… **MongoDB Integration**: Automatic data storage with deduplication
- âœ… **Intelligent Categorization**: Auto-classifies products into specific categories
- âœ… **Respectful Scraping**: Rate limiting and robots.txt compliance
- âœ… **Comprehensive Logging**: Detailed logging for monitoring and debugging
- âœ… **Error Handling**: Robust exception handling and recovery
- âœ… **Data Validation**: URL-based uniqueness and data integrity checks
- âœ… **Currency Auto-Detection**: Supports JOD, USD, EUR with smart extraction
- ğŸ†• **Hybrid Architecture**: Modular design with shared base class
- ğŸ†• **Code Reusability**: Eliminates duplication with BaseScraper class
- ğŸ†• **Centralized Database**: Single DatabaseManager for all operations
- ğŸ†• **Easy Testing**: Multiple test runners and validation scripts
- ğŸ†• **Flexible Execution**: Run scrapers individually or together
- ğŸ”¥ **Advanced Categorization**: 85.2% accuracy with 16+ product categories
- ğŸ”¥ **Arabic Language Support**: Native Arabic product name handling
- ğŸ”¥ **Market-Specific Logic**: Tailored for Jordanian electronics market
- ğŸ”¥ **Comprehensive Testing**: 27+ test cases covering edge scenarios

## ï¿½ Week 2 Improvements (September 2025)

### Enhanced Categorization System
Our categorization algorithm has been significantly improved for the Jordanian electronics market:

**ğŸ“Š Performance Metrics:**
- **85.2% categorization accuracy** (improved from 74.1%)
- **16+ product categories** (expanded from 11)
- **45+ Arabic keywords** for local market support
- **27 comprehensive test cases** covering edge scenarios

**ğŸŒ Market-Specific Features:**
- **Arabic Language Support**: Native handling of Arabic product names (Ù‡Ø§ØªÙ Ø°ÙƒÙŠ, ØªÙ„ÙØ²ÙŠÙˆÙ†, Ù…ÙƒÙŠÙ)
- **Jordanian Market Categories**: Air Conditioners, Kitchen Appliances, Power & Batteries
- **Local Brand Recognition**: Enhanced detection for regional electronics brands
- **Cultural Context**: Tailored categorization for Middle Eastern market preferences

**ğŸ”§ Technical Enhancements:**
- **Priority-Based Matching**: Resolves keyword conflicts intelligently
- **URL Pattern Recognition**: Enhanced fallback categorization from product URLs  
- **Brand-Based Classification**: Smart categorization using manufacturer context
- **Multi-Layer Fallback**: Comprehensive system ensures accurate categorization
- **Brand Pattern Specificity**: Fixed conflicts like "Vivo phone" vs "ASUS VivoBook" laptop
- **Processor-Aware Patterns**: Enhanced laptop detection with "book amd", "book intel", "book ryzen"

**ğŸ“ˆ Category Coverage:**
```
Mobile Phones & Tablets    Gaming & Entertainment
Computers & Laptops        Air Conditioners & Cooling  
Audio & Sound Systems      Power & Batteries
TVs & Monitors            Networking Equipment
Wearables & Fitness       Kitchen Appliances
Cameras & Photography     Small Home Appliances
Personal Care Products    Large Home Appliances
Accessories              Electronics (general)
```

### Hybrid Architecture Benefits (September 2025 Refactor)

The project has been refactored from monolithic scrapers to a **hybrid architecture** that combines:

**ğŸ”„ Shared Functionality (BaseScraper)**
- HTTP request handling with rate limiting
- HTML parsing and data extraction utilities
- Error handling and logging
- Dynamic field detection (currency, category, source)
- Database integration patterns

**ğŸ¯ Site-Specific Logic (Individual Scrapers)**
- Custom category link discovery
- Site-specific product selectors
- Unique URL patterns and parsing rules
- Website-specific optimization

**ğŸ”§ Benefits Achieved:**
- **90% code reduction** in duplicate functionality
- **Consistent behavior** across all scrapers
- **Easier maintenance** with centralized updates
- **Faster development** of new site scrapers
- **Better testing** with modular components

## ğŸ› ï¸ Technology Stack

- **Python 3.13**: Core programming language
- **BeautifulSoup4**: HTML parsing and data extraction
- **Requests**: HTTP client for web requests
- **MongoDB**: NoSQL database for flexible data storage
- **PyMongo**: MongoDB driver for Python

## ğŸ“ Project Structure

**âœ¨ Refactored to Hybrid Architecture (September 2025)**

```
jordan-electronics-scraper/
â”œâ”€â”€ src/                           # Main source code directory
â”‚   â”œâ”€â”€ scrapers/                  # Scraper implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py        # ğŸ†• Base class with shared functionality
â”‚   â”‚   â”œâ”€â”€ leaders_scraper.py     # ğŸ”„ Leaders.jo scraper (refactored)
â”‚   â”‚   â””â”€â”€ smartbuy_scraper.py    # ğŸ”„ SmartBuy scraper (refactored)
â”‚   â”œâ”€â”€ database/                  # Database operations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ manager.py             # ğŸ†• Centralized database manager
â”‚   â””â”€â”€ utils/                     # Shared utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py              # ğŸ†• Logging utilities
â”‚       â””â”€â”€ helpers.py             # ğŸ†• Helper functions
â”œâ”€â”€ tests/                         # Testing framework
â”‚   â”œâ”€â”€ test_refactored_system.py  # ğŸ†• Import and functionality tests
â”‚   â””â”€â”€ simple_test.py             # ğŸ†• Subprocess testing
â”œâ”€â”€ run_scraper.py                 # ğŸ†• Easy runner script
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file (updated!)
â”œâ”€â”€ Week1_Deliverables.txt        # Week 1 deliverables
â”œâ”€â”€ logs/                         # Log files
â”‚   â”œâ”€â”€ leaders_scraper.log
â”‚   â””â”€â”€ scraper.log
â””â”€â”€ venv/                         # Virtual environment

# Legacy files (kept for reference)
â”œâ”€â”€ leaders_scraper_old.py        # Original implementation
â””â”€â”€ smartbuy_scraper_old.py       # Original implementation
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.13+
- MongoDB (local installation or MongoDB Atlas)
- Git

### Installation

1. **Clone the repository**
   ```powershell
   git clone https://github.com/ammarpvl29/jordan-electronics-scraper.git
   cd jordan-electronics-scraper
   ```

2. **Create and activate virtual environment**
   ```powershell
   python -m venv venv
   venv\Scripts\Activate.ps1
   ```

3. **Install dependencies**
   ```powershell
   pip install -r requirements.txt
   ```

4. **Set up MongoDB**
   - Install MongoDB locally or use MongoDB Atlas
   - Ensure MongoDB is running on `localhost:27017`
   - The scrapers will automatically create the `jordan_electronics` database

### Running the Scrapers

**ğŸ†• Easy Runner (Recommended):**
```powershell
# Run individual scrapers
python run_scraper.py leaders    # Leaders scraper only
python run_scraper.py smartbuy   # SmartBuy scraper only
python run_scraper.py both       # Both scrapers

# Examples
python run_scraper.py leaders
python run_scraper.py both
```

**Direct Execution:**
```powershell
# Navigate to scraper directory first
cd src/scrapers

# Run individual scrapers
python leaders_scraper.py
python smartbuy_scraper.py
```

**ğŸ§ª Testing the System:**
```powershell
# Test all scrapers with timeout handling
python simple_test.py

# Test import system and functionality  
python test_refactored_system.py
```

## ğŸ“Š Data Collection

### Collected Product Fields

| Field | Type | Description | Example |
|-------|------|-------------|---------|
| `url` | String | Product page URL (unique identifier) | "https://smartbuy-me.com/product/..." |
| `title` | String | Product name/title | "Samsung WW70T3020BS 7KG Washer" |
| `price` | String | Price as displayed on website | "439.000 JOD" |
| `currency` | String | **Auto-detected** from price text | "JOD", "USD", "EUR" |
| `source_website` | String | **Auto-detected** from URL | "SmartBuy Jordan", "Leaders Center Jordan" |
| `category` | String | **Smart-detected** from content/URL | "Home Appliances", "Mobile Phones", "Wearables" |
| `brand` | String | Product manufacturer | "Samsung", "Apple", "Oppo" |
| `description` | String | Product description (first 200 chars) | "Samsung front-loading washer..." |
| `scraped_at` | DateTime | Data collection timestamp | "2025-09-21T10:30:00Z" |

### ğŸ¤– Smart Field Detection

#### Currency Detection
- **Automatic extraction** from price text using pattern matching
- **Supported currencies**: JOD (Ø¯.Ø§), USD ($), EUR (â‚¬)
- **Default fallback**: JOD (Jordan's currency)

#### Source Website Detection
- **URL-based identification**: Automatically detects website from product URL
- **Supported sites**: SmartBuy Jordan, Leaders Center Jordan
- **Extensible**: Automatically handles new domains

#### Category Classification
- **Intelligent categorization** based on URL patterns and product titles
- **Categories include**:
  - Mobile Phones (phone, smartphone, iphone, samsung, oppo)
  - Computers & Laptops (laptop, computer, pc, macbook)
  - Wearables (watch, smartwatch, fitness tracker)
  - Home Appliances (washing, dryer, refrigerator)
  - Audio & Sound (speaker, headphone, audio)
  - Personal Care (shaver, epilator, grooming)
  - Gaming (console, playstation, xbox)
  - TVs & Monitors (tv, monitor, display)
  - Cameras & Photography (camera, photo, video)
- **Fallback system**: Uses category from URL structure if specific detection fails

### Database Structure

- **Database**: `jordan_electronics`
- **Collections**:
  - `products`: Main product data
  - `scraping_logs`: Audit trail and monitoring

## ğŸ”§ Configuration

### MongoDB Configuration
- **Host**: `localhost:27017`
- **Database**: `jordan_electronics`
- **Authentication**: None (local development)

### Scraping Settings
- **User-Agent**: Custom headers to identify as legitimate browser
- **Rate Limiting**: 10-second delays for Leaders.jo
- **Timeout**: 30 seconds per request
- **Retries**: Automatic retry on failed requests

## ğŸ“ Logging

Each scraper generates detailed logs:
- **File Locations**: `./logs/` directory
- **Log Levels**: INFO, ERROR, WARNING
- **Content**: Requests, responses, errors, data collection metrics

## ğŸ§ª Testing

**ğŸ†• Comprehensive Testing Framework:**

- **`simple_test.py`**: Subprocess-based testing with timeout handling
  - Tests both scrapers independently
  - 60-second timeout per scraper
  - Captures output and return codes
  - Provides detailed success/failure reporting

- **`test_refactored_system.py`**: Import and functionality testing
  - Validates Python imports work correctly
  - Tests database connectivity
  - Verifies scraper instantiation
  - Checks shared functionality inheritance

- **`run_scraper.py`**: Manual testing and execution
  - Easy individual scraper testing
  - Combined scraper execution
  - Production and development modes

**Test Results from Latest Run (September 26, 2025):**
```
âœ… Leaders Scraper: PASSED
âœ… SmartBuy Scraper: PASSED (Unicode fixes applied)
ğŸ” SmartBuy Category Discovery: 198+ collections found
ï¿½ SmartBuy Brand Collections: 16+ brands supported
ï¿½ğŸ‰ Overall: 2/2 tests passed
```

**Latest SmartBuy Scraper Improvements:**
- **Unicode Compatibility**: Removed all Unicode emojis for Windows terminal support
- **Return Type Fix**: Fixed dictionary return format for category compatibility  
- **Comprehensive Discovery**: Successfully finds 6 core categories + 198 collections
- **Brand Support**: APPLE, SAMSUNG, SONY, ASUS, LENOVO, DELL, NESPRESSO, and more
- **Categorization Fix**: Resolved brand pattern conflicts (ASUS VivoBook correctly identified as laptop, not phone)

## ğŸ“ˆ Monitoring

### Success Metrics
- **Products Scraped**: Number of products collected per run
- **Success Rate**: Percentage of successful requests
- **Data Quality**: Completeness of product information
- **Error Rate**: Failed requests and parsing errors

### Health Checks
- Database connectivity
- Website accessibility
- Data validation
- Log file monitoring

## ğŸ”’ Ethical Scraping Practices

This project follows responsible web scraping guidelines:
- **Rate Limiting**: Respectful delays between requests
- **robots.txt Compliance**: Checking and following robots.txt rules
- **User-Agent Headers**: Proper identification
- **No Overloading**: Minimal server impact
- **Legal Compliance**: Following terms of service

## ğŸš§ Known Limitations

1. **JavaScript Content**: Currently handles static HTML only
2. **Site Changes**: Scraper updates needed if website structures change
3. **Rate Limits**: Manual delay management (no automatic adjustment)
4. **Error Recovery**: Basic retry logic implemented

## ğŸ“‹ Roadmap

**âœ… Completed (Week 1 + Refactoring):**
- âœ… Basic scraping functionality for 2 major Jordanian retailers
- âœ… MongoDB integration with comprehensive data storage
- âœ… Smart field detection (currency, category, source)
- âœ… **Hybrid architecture refactoring** (September 2025)
- âœ… **BaseScraper base class** with shared functionality
- âœ… **Centralized DatabaseManager** eliminating code duplication
- âœ… **Comprehensive testing framework** with multiple test approaches
- âœ… **Modular project structure** for better maintainability

**âœ… Completed (Week 2):**
- âœ… **Advanced categorization system** with 85.2% accuracy
- âœ… **Arabic language support** for Jordanian market
- âœ… **16+ product categories** covering electronics and appliances
- âœ… **Comprehensive test suite** with 27+ test scenarios
- âœ… **Market-specific optimizations** for Middle Eastern electronics

**ğŸ”„ In Progress (Week 2):**
- ğŸ”„ Daily automation implementation
- ğŸ”„ Scheduling system for regular scraping
- ğŸ”„ Enhanced monitoring and logging

**ğŸ¯ Week 2 Remaining (Due: October 3, 2025):**
- ğŸ”„ Complete daily automation system
- ğŸ”„ Windows Task Scheduler integration
- ğŸ”„ Production deployment procedures

**ğŸš€ Future Enhancements:**
- JavaScript content handling (dynamic pages)
- Advanced price trend analysis
- Real-time dashboard and monitoring
- API endpoints for data access
- Multi-threaded scraping capabilities
- Machine learning categorization improvements

## ğŸ“„ License

This project is for educational and research purposes. Please respect website terms of service and robots.txt files.

## ğŸ†˜ Troubleshooting

### Common Issues

**MongoDB Connection Error:**
```
pymongo.errors.ServerSelectionTimeoutError
```
**Solution**: Ensure MongoDB is running on localhost:27017

**Import Errors:**
```
ModuleNotFoundError: No module named 'requests'
```
**Solution**: Activate virtual environment and install requirements

**Scraping Failures:**
```
RequestException or parsing errors
```
**Solution**: Check internet connection and website accessibility

### Getting Help

1. Check log files in `./logs/` directory
2. Verify MongoDB connection
3. Ensure all dependencies are installed
4. Review error messages for specific issues

---

*Last Updated: September 26, 2025*  
*Version: 2.1.0 (Week 2 - Enhanced Categorization)*  
*Current Status: Week 2 Deliverable #1 Complete (85.2% categorization accuracy)*  
*Next Milestone: Daily Automation Implementation*